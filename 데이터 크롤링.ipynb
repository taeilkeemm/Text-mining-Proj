{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpHtprvxBQCq"
      },
      "source": [
        "import requests\n",
        "from pandas import DataFrame\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Oo_q9gMBQxK"
      },
      "source": [
        "date = str(datetime.now()) \n",
        "date = date[:date.rfind(':')].replace(' ', '_') \n",
        "date = date.replace(':','시') + '분' "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7FgiEGlBSii",
        "outputId": "3b169f8b-669d-44cf-dcf0-f5a94b74102e"
      },
      "source": [
        "query = input('검색 키워드를 입력하세요 : ') \n",
        "query = query.replace(' ', '+') \n",
        "\n",
        "news_num = int(input('총 필요한 뉴스기사 수를 입력해주세요(숫자만 입력) : ')) "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "검색 키워드를 입력하세요 : 주식\n",
            "총 필요한 뉴스기사 수를 입력해주세요(숫자만 입력) : 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZnlOkZsBUmq"
      },
      "source": [
        "news_url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={}'\n",
        "\n",
        "req = requests.get(news_url.format(query))\n",
        "soup = BeautifulSoup(req.text, 'html.parser')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTRPN5xOBcBi"
      },
      "source": [
        "news_dict = {} \n",
        "idx = 0 \n",
        "cur_page = 1"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4irEXjwBelh",
        "outputId": "1643f820-702f-4390-9fe6-a1c864f67c01"
      },
      "source": [
        "print()\n",
        "print('크롤링 중...')\n",
        "\n",
        "while idx < news_num:\n",
        "    \n",
        "    table = soup.find('ul',{'class' : 'list_news'})\n",
        "    li_list = table.find_all('li', {'id': re.compile('sp_nws.*')})\n",
        "    area_list = [li.find('div', {'class' : 'news_area'}) for li in li_list]\n",
        "    a_list = [area.find('a', {'class' : 'news_tit'}) for area in area_list]\n",
        "    \n",
        "    for n in a_list[:min(len(a_list), news_num-idx)]:\n",
        "        news_dict[idx] = {'title' : n.get('title'),\n",
        "                          'url' : n.get('href') }\n",
        "        idx += 1\n",
        "\n",
        "    cur_page += 1\n",
        "    \n",
        "    pages = soup.find('div', {'class' : 'sc_page_inner'})\n",
        "    next_page_url = [p for p in pages.find_all('a') if p.text == str(cur_page)][0].get('href')\n",
        "    \n",
        "    req = requests.get('https://search.naver.com/search.naver' + next_page_url)\n",
        "    soup = BeautifulSoup(req.text, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "크롤링 중...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTzX7QleBh9Z"
      },
      "source": [
        "print('크롤링 완료')\n",
        "\n",
        "print('데이터프레임 변환')\n",
        "news_df = DataFrame(news_dict).T\n",
        "\n",
        "folder_path = os.getcwd()\n",
        "xlsx_file_name = '네이버뉴스_{}_{}.xlsx'.format(query, date)\n",
        "\n",
        "news_df.to_excel(xlsx_file_name)\n",
        "\n",
        "print('엑셀 저장 완료 | 경로 : {}\\\\{}'.format(folder_path, xlsx_file_name))\n",
        "##os.startfile(folder_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq7HgvdzBk6y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}